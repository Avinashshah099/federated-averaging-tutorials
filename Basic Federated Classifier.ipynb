{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic federated classifier with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will see how to train a model using federated averaging.\n",
    "\n",
    "To begin a brief explanation of what it means to train using federated averaging with respect to training using a SyncReplicasOptimizer.\n",
    "\n",
    "In the previous tutorial, we explained that with SyncReplicasOptimizer each worker generated a gradient for its weights and wrote it to the parameter server. The chief read those gradients (including its own), it averaged them and updated the shared model.\n",
    "\n",
    "This time each worker will be updating its weights locally, as if it were the only one training. Every certain number of steps it will send its weights (not the gradients, but the weights themselves) to the parameter server. The chief will read the weights from there, it will average and write them again to the parameter server so that all the workers can overwrite theirs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire first part of the code is the same as the distributed classifier tutorial.\n",
    "\n",
    "Two differences only:\n",
    "\n",
    "- This time we also import __federated_average_optimizer__, the library with which we can federalize learning.\n",
    "- On the other hand we define the variable __INTERVAL_STEPS__. Every how many steps we will perform the average of the weights. Put another way, how many steps will each worker make in local before writing their weights in the parameter server and overwriting them with the average that the chief has made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import federated_averaging_optimizer\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"task_index\", None,\n",
    "                     \"Worker task index, should be >= 0. task_index=0 is \"\n",
    "                     \"the master worker task that performs the variable \"\n",
    "                     \"initialization \")\n",
    "flags.DEFINE_string(\"ps_hosts\", \"localhost:2222\",\n",
    "                    \"Comma-separated list of hostname:port pairs\")\n",
    "flags.DEFINE_string(\"worker_hosts\", \"localhost:2223,localhost:2224\",\n",
    "                    \"Comma-separated list of hostname:port pairs\")\n",
    "flags.DEFINE_string(\"job_name\", None, \"job name: worker or ps\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "INTERVAL_STEPS = 10\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "if FLAGS.job_name is None or FLAGS.job_name == \"\":\n",
    "    raise ValueError(\"Must specify an explicit `job_name`\")\n",
    "if FLAGS.task_index is None or FLAGS.task_index == \"\":\n",
    "    raise ValueError(\"Must specify an explicit `task_index`\")\n",
    "\n",
    "if FLAGS.task_index == 0:\n",
    "    print('--- GPU Disabled ---')\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "#Construct the cluster and start the server\n",
    "ps_spec = FLAGS.ps_hosts.split(\",\")\n",
    "worker_spec = FLAGS.worker_hosts.split(\",\")\n",
    "\n",
    "# Get the number of workers.\n",
    "num_workers = len(worker_spec)\n",
    "print('{} workers defined'.format(num_workers))\n",
    "\n",
    "cluster = tf.train.ClusterSpec({\"ps\": ps_spec, \"worker\": worker_spec})\n",
    "\n",
    "server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)\n",
    "if FLAGS.job_name == \"ps\":\n",
    "    print('--- Parameter Server Ready ---')\n",
    "    server.join()\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "print('Data loaded')\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "train_images = np.split(train_images, num_workers)[FLAGS.task_index]\n",
    "train_labels = np.split(train_labels, num_workers)[FLAGS.task_index]\n",
    "print('Local dataset size: {}'.format(train_images.shape[0]))\n",
    "\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "is_chief = (FLAGS.task_index == 0)\n",
    "\n",
    "checkpoint_dir='logs_dir/{}'.format(time())\n",
    "print('Checkpoint directory: ' + checkpoint_dir)\n",
    "\n",
    "worker_device = \"/job:worker/task:%d\" % FLAGS.task_index\n",
    "print('Worker device: ' + worker_device + ' - is_chief: {}'.format(is_chief))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we begin the definition of the graph in the same way as it was done in the basic classifier, until we reach the definition of the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "with tf.name_scope('dataset'):\n",
    "    images_placeholder = tf.placeholder(train_images.dtype, [None, train_images.shape[1], train_images.shape[2]], name='images_placeholder')\n",
    "    labels_placeholder = tf.placeholder(train_labels.dtype, [None], name='labels_placeholder')\n",
    "    batch_size = tf.placeholder(tf.int64, name='batch_size')\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images_placeholder, labels_placeholder))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.repeat(EPOCHS)\n",
    "    iterator = tf.data.Iterator.from_structure(dataset.output_types, dataset.output_shapes)\n",
    "    dataset_init_op = iterator.make_initializer(dataset, name='dataset_init')\n",
    "    X, y = iterator.get_next()\n",
    "\n",
    "flatten_layer = tf.layers.flatten(X, name='flatten')\n",
    "\n",
    "dense_layer = tf.layers.dense(flatten_layer, 128, activation=tf.nn.relu, name='relu')\n",
    "\n",
    "predictions = tf.layers.dense(dense_layer, 10, activation=tf.nn.softmax, name='softmax')\n",
    "\n",
    "summary_averages = tf.train.ExponentialMovingAverage(0.9)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(keras.losses.sparse_categorical_crossentropy(y, predictions))\n",
    "    loss_averages_op = summary_averages.apply([loss])\n",
    "    tf.summary.scalar('cross_entropy', summary_averages.average(loss))\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.cast(y, tf.int64))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy_metric')\n",
    "    accuracy_averages_op = summary_averages.apply([accuracy])\n",
    "    tf.summary.scalar('accuracy', summary_averages.average(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the __replica_device_setter__ in the distributed learning to automatically choose in which device to place each defined op. Here we create it just to pass it as an argument to the custom optimizer that we have created to contain the logic of the federated averaging.\n",
    "\n",
    "This custom optimizer will use the __replica_device_setter__ to place a copy of each trainable variable in the ps, this new variables will store the averaged values of all the local models.\n",
    "\n",
    "Once this optimizer has been defined, we create the training operation and a, in the same way as we did with SyncReplicasOptimizer, a hook that will run inside the MonitoredTrainingSession, which handles the synchronization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    device_setter = tf.train.replica_device_setter(worker_device=worker_device, cluster=cluster)\n",
    "    optimizer = federated_averaging_optimizer.FederatedAveragingOptimizer(tf.train.AdamOptimizer(np.sqrt(num_workers) * 0.001), replicas_to_aggregate=num_workers, interval_steps=INTERVAL_STEPS, device_setter=device_setter)\n",
    "    with tf.control_dependencies([loss_averages_op, accuracy_averages_op]):\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    model_average_hook = optimizer.make_session_run_hook(is_chief=is_chief)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep defining our hooks as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = int(train_images.shape[0] / BATCH_SIZE)\n",
    "last_step = int(n_batches * EPOCHS)\n",
    "\n",
    "print('Graph definition finished')\n",
    "\n",
    "sess_config = tf.ConfigProto(\n",
    "    allow_soft_placement=True,\n",
    "    log_device_placement=False,\n",
    "    operation_timeout_in_ms=20000,\n",
    "    device_filters=[\"/job:ps\",\n",
    "    \"/job:worker/task:%d\" % FLAGS.task_index])\n",
    "\n",
    "print('Training {} batches...'.format(last_step))\n",
    "\n",
    "class _LoggerHook(tf.train.SessionRunHook):\n",
    "  def begin(self):\n",
    "      self._total_loss = 0\n",
    "      self._total_acc = 0\n",
    "\n",
    "  def before_run(self, run_context):\n",
    "      return tf.train.SessionRunArgs([loss, accuracy, global_step])\n",
    "\n",
    "  def after_run(self, run_context, run_values):\n",
    "      loss_value, acc_value, step_value = run_values.results\n",
    "      self._total_loss += loss_value\n",
    "      self._total_acc += acc_value\n",
    "      if (step_value + 1) % n_batches == 0 and not step_value == 0:\n",
    "          print(\"Epoch {}/{} - loss: {:.4f} - acc: {:.4f}\".format(int(step_value / n_batches) + 1, EPOCHS, self._total_loss / n_batches, self._total_acc / n_batches))\n",
    "          self._total_loss = 0\n",
    "          self._total_acc = 0\n",
    "\n",
    "class _InitHook(tf.train.SessionRunHook):\n",
    "    def after_create_session(self, session, coord):\n",
    "        session.run(dataset_init_op, feed_dict={images_placeholder: train_images, labels_placeholder: train_labels, batch_size: BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shared variables generated within the custom optimizer get their initialized value from their corresponding trainable variables in the local worker. Therefore their initialization ops will be unavailable out of this session even if we try to restore a saved checkpoint.\n",
    "\n",
    "We need to define a custom saver which ignores this shared variables. In this case, we only save the trainable_variables ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _SaverHook(tf.train.SessionRunHook):\n",
    "    def begin(self):\n",
    "        self._saver = tf.train.Saver(tf.trainable_variables())\n",
    "\n",
    "    def before_run(self, run_context):\n",
    "        return tf.train.SessionRunArgs(global_step)\n",
    "\n",
    "    def after_run(self, run_context, run_values):\n",
    "        step_value = run_values.results\n",
    "        if step_value % n_batches == 0 and not step_value == 0:\n",
    "            self._saver.save(run_context.session, checkpoint_dir+'/model.ckpt', step_value)\n",
    "\n",
    "    def end(self, session):\n",
    "        self._saver.save(session, checkpoint_dir+'/model.ckpt', session.run(global_step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution of the training session is standard. Notice the new hook that we have added to the hook lists, and the ___SaverHook__ that will only be executed by the chief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('monitored_session'):\n",
    "    with tf.train.MonitoredTrainingSession(\n",
    "            master=server.target,\n",
    "            is_chief=is_chief,\n",
    "            checkpoint_dir=checkpoint_dir,\n",
    "            hooks=[_LoggerHook(), _InitHook(), model_average_hook],\n",
    "            chief_only_hooks=[_SaverHook()],\n",
    "            config=sess_config,\n",
    "            stop_grace_period_secs=10,\n",
    "            save_checkpoint_secs=None) as mon_sess:\n",
    "        while not mon_sess.should_stop():\n",
    "            mon_sess.run(train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_chief:\n",
    "    print('--- Begin Evaluation ---')\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        saver = tf.train.import_meta_graph(ckpt.model_checkpoint_path + '.meta', clear_devices=True)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print('Model restored')\n",
    "        graph = tf.get_default_graph()\n",
    "        images_placeholder = graph.get_tensor_by_name('dataset/images_placeholder:0')\n",
    "        labels_placeholder = graph.get_tensor_by_name('dataset/labels_placeholder:0')\n",
    "        batch_size = graph.get_tensor_by_name('dataset/batch_size:0')\n",
    "        accuracy = graph.get_tensor_by_name('accuracy/accuracy_metric:0')\n",
    "        predictions = graph.get_tensor_by_name('softmax/BiasAdd:0')\n",
    "        dataset_init_op = graph.get_operation_by_name('dataset/dataset_init')\n",
    "        sess.run(dataset_init_op, feed_dict={images_placeholder: test_images, labels_placeholder: test_labels, batch_size: test_images.shape[0]})\n",
    "        print('Test accuracy: {:4f}'.format(sess.run(accuracy)))\n",
    "        predicted = sess.run(predictions)\n",
    "\n",
    "    # Plot the first 25 test images, their predicted label, and the true label\n",
    "    # Color correct predictions in green, incorrect predictions in red\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(test_images[i], cmap=plt.cm.binary)\n",
    "        predicted_label = np.argmax(predicted[i])\n",
    "        true_label = test_labels[i]\n",
    "        if predicted_label == true_label:\n",
    "          color = 'green'\n",
    "        else:\n",
    "          color = 'red'\n",
    "        plt.xlabel(\"{} ({})\".format(class_names[predicted_label],\n",
    "                                    class_names[true_label]),\n",
    "                                    color=color)\n",
    "\n",
    "    plt.show(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
